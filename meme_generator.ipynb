{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(counter):\n",
    "    \"\"\" Converts a letter -> count counter to a list of (letter, \n",
    "    frequency) pairs, sorted in descending order of frequency.\n",
    "    \n",
    "        Parameters\n",
    "        -----------\n",
    "        counter : collections.Counter\n",
    "            letter -> count\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        A list of (letter, frequency) pairs, sorted in descending \n",
    "        order of frequency. \"\"\"\n",
    "\n",
    "    total = sum(counter.values())\n",
    "    return [(char, cnt/total) for char, cnt in counter.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_lm(text, n):\n",
    "    \"\"\" Trains a character-based n-gram language model.\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        text: str \n",
    "            \n",
    "        n: int\n",
    "            the length of the n-gram to analyze.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        A dictionary that maps history to a list of tuples that \n",
    "        describes the probability of each following character. \"\"\"\n",
    "    \n",
    "    raw_lm = defaultdict(Counter)\n",
    "    # no padding characters so that generated text starts with different letter combinations\n",
    "    history = text[:n - 1]\n",
    "    \n",
    "    for char in text[n - 1:]:\n",
    "        raw_lm[history][char] += 1\n",
    "        history = history[1:] + char\n",
    "    \n",
    "    lm = {history : normalize(counter) for history, counter in raw_lm.items()}\n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_letter(lm, history):\n",
    "    \"\"\" Randomly generates a letter according to the probability \n",
    "    distribution associated with the specified history.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        lm: Dict[str, List[Tuple[str, float]]] \n",
    "            the n-gram language model. \n",
    "        \n",
    "        history: str\n",
    "            a string of length (n-1) to use as history when generating \n",
    "            the next character.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        The predicted character. \"\"\"\n",
    "    \n",
    "    if not history in lm:\n",
    "        # ends sentence\n",
    "        return '.'\n",
    "    letters, probs = tuple(zip(*lm[history]))\n",
    "    i = np.random.choice(letters, p=probs)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sentence(lm, n):\n",
    "    \"\"\" Randomly generates a sentence by drawing from the probability \n",
    "    distributions stored in the n-gram language model.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        lm: Dict[str, List[Tuple[str, float]]]\n",
    "            the n-gram language model. \n",
    "            \n",
    "        n: int\n",
    "            order of n-gram model.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Model-generated sentence. \"\"\"\n",
    "    \n",
    "    # chooses a random word to start with as history\n",
    "    word_start_hist = [hist for hist in lm.keys() if hist.startswith(' ')]\n",
    "    i = np.random.randint(len(word_start_hist))\n",
    "    history = word_start_hist[i]\n",
    "    \n",
    "    text = []\n",
    "    text.extend(history[1:])\n",
    "    \n",
    "    spaces = 0\n",
    "    \n",
    "    while True:\n",
    "        c = generate_letter(lm, history)\n",
    "        if c == '.':\n",
    "            break\n",
    "        text.append(c)\n",
    "        history = history[1:] + c\n",
    "        \n",
    "    return \"\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose(*choices):\n",
    "    i = np.random.randint(len(choices))\n",
    "    return choices[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle():\n",
    "    with open(\"nouns.txt\", \"r\") as f:\n",
    "        nouns = f.read()\n",
    "    nouns = list(set(nouns.split()))\n",
    "\n",
    "    with open(\"verbs.txt\", \"r\") as f:\n",
    "        verbs = f.read()\n",
    "    verbs = list(set(verbs.split()))\n",
    "\n",
    "    with open(\"adjs.txt\", \"r\") as f:\n",
    "        adjs = f.read()\n",
    "    adjs = list(set(adjs.split()))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noun():\n",
    "    return nouns[np.random.randint(len(nouns))]\n",
    "\n",
    "def adj():\n",
    "    return adjs[np.random.randint(len(adjs))]\n",
    "\n",
    "def verb():\n",
    "    return verbs[np.random.randint(len(verbs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_meme():\n",
    "    unpickle()\n",
    "    \n",
    "    pronouns = [\"him\", \"her\"]\n",
    "    \n",
    "    jokes = [\"*slaps roof of {0}*. \\nThis {0} can fit so much {1} {2} in it.\".format(noun(), adj(), noun()),\n",
    "             \"Thank you {} very {}.\".format(noun(), adj()),\n",
    "             \"This is so {} Alexa play {}.\".format(adj(), choose(noun().capitalize(), adj().capitalize(), verb().capitalize(), adj().capitalize() + ' ' + noun().capitalize())),\n",
    "             \"Dad, why is my sister's name {0} {1}? \\nBecause your mother loves {0} {1}. \\nThanks Dad. \\nNo problem {2}.\".format(adj().capitalize(), noun().capitalize(), noun().capitalize()),\n",
    "             \"Please stop making these dang challenges so hard @FortniteGame. \\n{} a {}.\".format(verb().capitalize(), noun()),\n",
    "             \"{} announces {} {}. \\n{} rate drops to 0%.\".format(noun().capitalize(), noun().capitalize(), str(np.random.randint(1, 11)), noun().capitalize()),\n",
    "             \"{} are now statistically more popular than {}.\".format((noun() + 's').capitalize(), noun() + 's'),\n",
    "             \"You can't {} a {} if you don't {} a {}.\".format(verb(), noun(), verb(), noun()),\n",
    "             \"{} are just {}. \\nChange my mind.\".format((noun() + 's').capitalize(), choose(adj() + ' ' + noun() + 's', adj())),\n",
    "             \"{} {} is the most ambitious crossover event in history.\".format(adj().capitalize(), noun().capitalize()),\n",
    "             'When Drake said \"{},\" I felt that.'.format(choose(adj() + ' ' + noun(), noun() + 's ' + verb(), adj() + ' ' + noun() + 's ' + verb())),\n",
    "             \"You: {} {} {}. \\nMe, an intellectual: {} {} {}.\".format(adj().capitalize(), noun() + 's', verb(), adj().capitalize(), noun() + 's', verb()),\n",
    "             \"Petition: Make {} {}. 6,953 have signed. Let's get to 7,500!\".format(noun(), verb()),\n",
    "             \"Is it normal to {} your {}? \\n{} wants to know your location.\".format(verb(), noun(), noun().capitalize()),\n",
    "             \"Who would win? \\n{} {}. \\nOne {} boi.\".format(str(np.random.randint(1000, 10000)), noun() + 's', adj()),\n",
    "             \"You wouldn't {} a {}.\".format(verb(), noun())]\n",
    "    i = np.random.randint(len(jokes))    \n",
    "    return jokes[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nouns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9d7eff203b66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_meme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-8c85afa20382>\u001b[0m in \u001b[0;36mgenerate_meme\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpronouns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"him\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"her\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     jokes = [\"*slaps roof of {0}*. \\nThis {0} can fit so much {1} {2} in it.\".format(noun(), adj(), noun()),\n\u001b[0m\u001b[1;32m      7\u001b[0m              \u001b[0;34m\"Thank you {} very {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m              \u001b[0;34m\"This is so {} Alexa play {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ab30e487fffc>\u001b[0m in \u001b[0;36mnoun\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnoun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnouns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnouns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0madjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nouns' is not defined"
     ]
    }
   ],
   "source": [
    "print(generate_meme())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
